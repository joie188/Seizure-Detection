{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31036229c425e6c56cb80787aff8b8b0bf677f7f5526fbbc178d08736b2406a8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## SVM\n",
    "RBF Kernel, C=100, gamma=0.01"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import time\n",
    "import math \n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cvxopt import solvers\n",
    "solvers.options['show_progress'] = False\n",
    "from cvxopt import matrix\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.metrics import recall_score"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ker_linear = lambda X1, X2: X1.dot(X2.T)\n",
    "\n",
    "def kernel_rbf(X1, X2, gamma):\n",
    "    if len(X1.shape) == 1:\n",
    "        X1 = X1.reshape(1, -1) # (N1, d)\n",
    "    if len(X2.shape) == 1:\n",
    "        X2 = X2.reshape(1, -1) # (N2, d)\n",
    "    X1 = np.expand_dims(X1, axis=1) # (N1, 1, d)\n",
    "    X2 = np.expand_dims(X2, axis=0) # (1, N2, d)\n",
    "    \n",
    "    # broadcasting trick\n",
    "    return np.exp(-gamma * np.sum((X1 - X2) ** 2, axis=2))\n",
    "\n",
    "def train_kernel_svm(X, y, k, C, gamma):\n",
    "    \"\"\"\n",
    "    inputs\n",
    "    X: data matrix, shape (N, d)\n",
    "    y: label matrix, shape (N,)\n",
    "    k: if k is None, then compute the kernel by XX^T; else k could be a function or precomputed matrix\n",
    "    C: coefficient of slack terms in primal optimization, scalar \n",
    "    \n",
    "    returns\n",
    "    w: weight, shape (N,)\n",
    "    b: bias, scalar\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    N = len(y)\n",
    "    if callable(k):\n",
    "        # print(\"kernel!\")\n",
    "        K = k(X, X, gamma)\n",
    "    elif k is None:\n",
    "        k = ker_linear\n",
    "        K = X.dot(X.T)\n",
    "    else:\n",
    "        K = k\n",
    "    # prints(K)\n",
    "\n",
    "    P = K.reshape(N, N) * y.reshape(N, 1).dot(y.reshape(1, N))\n",
    "    q = -np.ones(N)\n",
    "\n",
    "    G = np.concatenate((np.eye(N), -np.eye(N)))\n",
    "    # h = np.concatenate((C * np.ones(N), np.zeros(N)))\n",
    "    \n",
    "    C_pos = (np.count_nonzero(y == 1)/N)*C  \n",
    "    C_neg = (np.count_nonzero(y == -1)/N)*C \n",
    "    # print(C_pos, C_neg)\n",
    "\n",
    "    y_C = np.zeros(N)\n",
    "    pos = np.where(y == 1)\n",
    "    neg = np.where(y == -1)\n",
    "    y_C[pos] = C_pos \n",
    "    y_C[neg] = C_neg \n",
    "    h = np.concatenate((y_C, np.zeros(N)))\n",
    "    \n",
    "    A = y.reshape(1, N)\n",
    "    A = A.astype('float')\n",
    "    b = np.zeros(1)\n",
    "    \n",
    "    sol = solvers.qp(matrix(P), matrix(q), matrix(G), matrix(h), matrix(A), matrix(b))\n",
    "    # print(\"done\")\n",
    "    alpha = np.array(sol['x'])\n",
    "    # print(alpha)\n",
    "    alpha[alpha < 1e-4] = 0\n",
    "    alpha = alpha.reshape(-1)\n",
    "    \n",
    "    # is_support_vector = (0 < alpha) & (alpha < C)\n",
    "\n",
    "    is_support_vector = []\n",
    "    for i in range(len(alpha)):\n",
    "        value = False\n",
    "        if alpha[i] > 0:\n",
    "            if y[i] == -1:\n",
    "                value = abs(alpha[i] - C_neg) <= 0.01\n",
    "            elif y[i] == 1:\n",
    "                value = abs(alpha[i] - C_pos) <= 0.01 \n",
    "        is_support_vector.append(value)\n",
    "\n",
    "    y_sv = y[is_support_vector]\n",
    "    X_sv = X[is_support_vector]\n",
    "    b = (y_sv - ((alpha * y).reshape(-1, 1)*k(X, X_sv, gamma)).sum(axis=0)).mean()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"SVM training time:\", end_time - start_time, \"s\")\n",
    "    return alpha, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_kernel_svm(alpha, b, X, y, ker, gamma=1):\n",
    "    return lambda x: (alpha * y * ker(X, x, gamma).reshape(-1)).sum(axis=0) + b\n",
    "\n",
    "def svm_score(alpha, b, X_train, y_train, X, y, ker, gamma=1):\n",
    "    pred_kernel_svm = get_pred_kernel_svm(alpha, b, X_train, y_train, ker, gamma)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    preds = np.array([pred_kernel_svm(x) for x in X])\n",
    "\n",
    "    score = (preds * y > 0).mean()\n",
    "    print(score)\n",
    "    print(preds)\n",
    "    precision = precision_score(y, np.sign(preds), average='binary')\n",
    "    recall = recall_score(y, np.sign(preds), average='binary')\n",
    "    \n",
    "    end_time = time.time() \n",
    "    print(\"SVM eval time:\", end_time - start_time, \"s\")\n",
    "    return score, precision, recall"
   ]
  },
  {
   "source": [
    "## KNN \n",
    "Chi-squared distance\n",
    "K=71\n",
    "Features=cwt energy bands, std, energy, max"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_squared_distance(A, B):\n",
    "    return 0.5* np.sum(((A-B)**2) / (A+B), axis=0)\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, K, distance_metric, trainX, trainY):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            K is an int representing the number of closest neighbors to consider\n",
    "            distance_metric is one of euclidean or manhattan\n",
    "            trainX is d by n array\n",
    "            trainY is 1 by n array\n",
    "        \"\"\"\n",
    "        self.trainX = trainX\n",
    "        self.trainY = trainY\n",
    "        self.pos_size = np.count_nonzero(self.trainY == 1)\n",
    "        self.neg_size = np.count_nonzero(self.trainY == -1)\n",
    "        self.K = K\n",
    "        self.metric = distance_metric\n",
    "\n",
    "    def calc_distances(self, testX):\n",
    "        dists = np.vstack([self.metric(self.trainX, testX[:, i:i+1]) for i in range(testX.shape[1])])\n",
    "        return dists\n",
    "        \n",
    "    def find_top_neighbor_labels(self, dists):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            dists is  m x n array D where D[i, j] is the distance between test sample i and train sample j\n",
    "        Returns:\n",
    "            an m x K array L where L[i, j] is the label of the jth closest neighbor to test sample i\n",
    "            in case of ties, the neighbor which appears first in the training set is chosen\n",
    "        \"\"\"\n",
    "        neighbors = np.argsort(dists)[:, :self.K]\n",
    "        neighbor_labels = self.trainY.squeeze()[neighbors]\n",
    "        return neighbor_labels\n",
    "\n",
    "    def find_top_neighbor(self, dists):\n",
    "        top_distances = np.sort(dists)[:, :self.K]\n",
    "        top_labels = self.trainY.squeeze()[np.argsort(dists)[:, :self.K]]\n",
    "        return top_distances, top_labels\n",
    "    \n",
    "    def predict(self, testX):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            testX is d by m array\n",
    "        Returns:\n",
    "            predicted is 1 x m array P where P[0, i] is the predicted label for test sample i \n",
    "        \"\"\"\n",
    "        neighbor_labels = self.find_top_neighbor_labels(self.calc_distances(testX))\n",
    "        neighbor_labels = neighbor_labels.astype(int)\n",
    "        predicted = np.hstack([np.bincount(vals).argmax() for vals in neighbor_labels])\n",
    "        return predicted\n",
    "    \n",
    "    def score(self, testX, testY):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            testX is d by m array of input data\n",
    "            testY is 1 by m array of labels for the input data\n",
    "        Returns:\n",
    "            the accuracy of the KNN predictions across the test set\n",
    "        \"\"\"\n",
    "        \n",
    "        start_time = time.time()\n",
    "        pred = self.predict(testX)\n",
    "        # print(\"Precision:\", precision_score(testY, pred, average='binary'))\n",
    "        # print(\"Recall:\", recall_score(testY, pred, average='binary'))\n",
    "        precision = precision_score(testY, pred, average='binary')\n",
    "        recall = recall_score(testY, pred, average='binary')\n",
    "        score = np.sum(pred == testY) / len(testY)\n",
    "        end_time = time.time()\n",
    "        print(\"KNN eval time:\", end_time - start_time, \"s\")\n",
    "        return score, precision, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def train_knn(X, y, distance, k):\n",
    "    start_time = time.time()\n",
    "    oversample = SMOTE()\n",
    "    x_tmp, y_tmp = oversample.fit_resample(X, y)\n",
    "    classifier = KNN(k, distance, x_tmp.T, y_tmp)\n",
    "    end_time = time.time()\n",
    "    print(\"KNN training time:\", end_time - start_time, \"s\") # should be fairly negligible?\n",
    "    return classifier"
   ]
  },
  {
   "source": [
    "## Random Forest \n",
    "100 trees, 10 samples per leaf"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature, value, num_samples_seizure, num_samples_noseizure):\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.num_samples_seizure = num_samples_seizure\n",
    "        self.num_samples_noseizure = num_samples_noseizure\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, num_trees, min_samples_leaf, trainX, trainY, samples_per_tree=None, features_per_tree=None, features_to_train_on = None):\n",
    "        '''\n",
    "        samples_per_tree is the number of samples (with replacement) used to construct each tree\n",
    "        features_per_tree is the number of features to consider when making splits in each tree\n",
    "        features_to_train_on is a list of indices that correspond to features, if None: all features are used\n",
    "        '''\n",
    "        self.num_trees = num_trees\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.trainX = trainX\n",
    "        self.trainY = trainY\n",
    "        self.pos_size = np.count_nonzero(self.trainY == 1)\n",
    "        self.neg_size = np.count_nonzero(self.trainY == -1)\n",
    "        self.trees = []\n",
    "\n",
    "        if samples_per_tree is None:\n",
    "            self.samples_per_tree = trainX.shape[0]\n",
    "        else:\n",
    "            self.samples_per_tree = samples_per_tree\n",
    "\n",
    "        if features_per_tree is None:\n",
    "            self.features_per_tree = int(math.sqrt(trainX.shape[1]))\n",
    "        else:\n",
    "            self.features_per_tree = features_per_tree\n",
    "        \n",
    "        if features_to_train_on is None:\n",
    "            self.features_to_train_on = np.arange(trainX.shape[1])\n",
    "        else:\n",
    "            self.features_to_train_on = features_to_train_on\n",
    "    \n",
    "    def build_tree(self, data_indices, features, weights):\n",
    "        best_feature, best_val, best_left, best_right = self.best_split(data_indices, features, weights)\n",
    "        if best_feature is None:\n",
    "            return None\n",
    "        root = Node(best_feature, best_val, np.count_nonzero(self.trainY[data_indices] == 1), len(data_indices) - np.count_nonzero(self.trainY[data_indices] == 1))\n",
    "        root.left = self.build_tree(best_left, features, weights)\n",
    "        root.right = self.build_tree(best_right, features, weights)\n",
    "        return root\n",
    "\n",
    "    def train(self):\n",
    "        self.trees = []\n",
    "        for _ in range(self.num_trees):\n",
    "            #randomly sample from X with replacement\n",
    "            samples_indices = np.random.choice(self.trainX.shape[0], size=self.samples_per_tree, replace=True)\n",
    "\n",
    "            #randomly choose features to consider\n",
    "            features = np.random.choice(self.features_to_train_on, size=self.features_per_tree, replace=False)\n",
    "\n",
    "            positive_class_count = np.count_nonzero(self.trainY[samples_indices] == 1)\n",
    "            negative_class_count = self.samples_per_tree - positive_class_count\n",
    "\n",
    "            tree = self.build_tree(samples_indices, features, (1.0 / positive_class_count, 1.0 / negative_class_count))\n",
    "\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, testX):\n",
    "        '''\n",
    "        label of 1 = seizure, label of 0 = no seizure\n",
    "        '''\n",
    "        predictions = np.zeros(testX.shape[0])\n",
    "        for i in range(testX.shape[0]):\n",
    "            predict_proba = self.predict_proba_ensemble(testX[i])\n",
    "            if predict_proba[0] > predict_proba[1]:\n",
    "                predictions[i] = 1\n",
    "            else:\n",
    "                predictions[i] = -1\n",
    "        return predictions\n",
    "\n",
    "    def predict_proba_ensemble(self, x):\n",
    "        '''\n",
    "        returns mean (prob seizure, prob no seizure)\n",
    "        '''\n",
    "        probs_seizure = 0\n",
    "        probs_noseizure = 0\n",
    "        for tree in self.trees:\n",
    "            (prob_seizure, prob_noseizure) = self.predict_proba(x, tree)\n",
    "            probs_seizure += prob_seizure\n",
    "            probs_noseizure += prob_noseizure\n",
    "        return (probs_seizure, probs_noseizure)\n",
    "\n",
    "    def predict_proba(self, x, tree):\n",
    "        '''\n",
    "        x is a row of data\n",
    "        returns (prob of seizure, prob of not seizure)\n",
    "        '''\n",
    "        #seizure_weight = 1.0 / tree.num_samples_seizure\n",
    "        #noseizure_weight = 1.0 / tree.num_samples_noseizure\n",
    "        while tree is not None:\n",
    "            if x[tree.feature] <= tree.value:\n",
    "                if tree.left is None:\n",
    "                    return (float(tree.num_samples_seizure) / (tree.num_samples_seizure + tree.num_samples_noseizure), float(tree.num_samples_noseizure) / (tree.num_samples_seizure + tree.num_samples_noseizure))\n",
    "                tree = tree.left\n",
    "            else:\n",
    "                if tree.right is None:\n",
    "                    return (float(tree.num_samples_seizure) / (tree.num_samples_seizure + tree.num_samples_noseizure), float(tree.num_samples_noseizure) / (tree.num_samples_seizure + tree.num_samples_noseizure))\n",
    "                tree = tree.right\n",
    "\n",
    "    def perform_split(self, data, feature, split_val):\n",
    "        left = []\n",
    "        right = []\n",
    "        for row_index in data:\n",
    "            if self.trainX[row_index][feature] <= split_val:\n",
    "                left.append(row_index)\n",
    "            else:\n",
    "                right.append(row_index)\n",
    "        return left, right\n",
    "    \n",
    "    def best_split(self, data, features, weights):\n",
    "        best_score = 2**31-1\n",
    "        best_feature, best_val, best_left, best_right = None, None, None, None\n",
    "        for index in features:\n",
    "            feature, val, left, right, score = self.find_split(data, index, weights)\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_feature, best_val, best_left, best_right = feature, val, left, right\n",
    "        return best_feature, best_val, best_left, best_right\n",
    "\n",
    "    def find_split(self, data, feature, weights):\n",
    "        best_score = 2**31-1\n",
    "        left = None\n",
    "        right = None\n",
    "        val = None\n",
    "        for row_index in data:\n",
    "            split_val = self.trainX[row_index][feature]\n",
    "            left_temp, right_temp = self.perform_split(data, feature, split_val)\n",
    "            if len(left_temp) < self.min_samples_leaf or len(right_temp) < self.min_samples_leaf:\n",
    "                continue\n",
    "            split_gini_score = self.gini_score([left_temp, right_temp], weights)\n",
    "            if split_gini_score < best_score:\n",
    "                best_score = split_gini_score\n",
    "                left = left_temp\n",
    "                right = right_temp\n",
    "                val = split_val\n",
    "        return feature, val, left, right, best_score\n",
    "\n",
    "    def gini_score(self, splits, weights):\n",
    "        '''\n",
    "        splits is list of lists where each list has indices into trainX of rows in that group\n",
    "        '''\n",
    "        gini = 0\n",
    "        all_samples = [index for split in splits for index in split]\n",
    "        positive_class_weight = weights[0]\n",
    "        negative_class_weight = weights[1]\n",
    "        t_p = positive_class_weight * np.count_nonzero(self.trainY[all_samples] == 1) + negative_class_weight * np.count_nonzero(self.trainY[all_samples] == -1)\n",
    "        for split in splits:\n",
    "            if len(split) == 0:\n",
    "                continue\n",
    "            split_score = 0\n",
    "            positive_class_count = np.count_nonzero(self.trainY[split] == 1) #seizure\n",
    "            negative_class_count = np.count_nonzero(self.trainY[split] == -1) \n",
    "            t_c = positive_class_weight * positive_class_count + negative_class_weight * negative_class_count\n",
    "            split_score += (positive_class_weight * positive_class_count/t_c) ** 2\n",
    "            split_score += (negative_class_weight * negative_class_count/t_c) ** 2\n",
    "            gini += t_c/t_p * (1.0 - split_score) \n",
    "        return gini\n",
    "\n",
    "    def score(self, testX, testY):\n",
    "        start_time = time.time()\n",
    "        pred = self.predict(testX)\n",
    "        score = np.sum(pred == testY) / testX.shape[0]\n",
    "        precision = precision_score(testY, pred, average='binary')\n",
    "        recall = recall_score(testY, pred, average='binary')\n",
    "        end_time = time.time()\n",
    "        print(\"Random Forest eval time:\", end_time - start_time, \"s\")\n",
    "        return score, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rfc(X, y, num_tree, num_sample):\n",
    "    start_time = time.time()\n",
    "    classifier = RandomForest(num_tree, num_sample, X, y, samples_per_tree=500)\n",
    "    classifier.train()\n",
    "    end_time = time.time()\n",
    "    print(\"Random Forest training time:\", end_time - start_time, \"s\") # should be fairly negligible?\n",
    "    return classifier"
   ]
  },
  {
   "source": [
    "## Ensemble"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters \n",
    "# SVM\n",
    "C = 1\n",
    "gamma = 0.01 \n",
    "kernel = kernel_rbf\n",
    "\n",
    "# KNN\n",
    "features = [14, 13, 4, 7, 12, 1, 15, 10] \n",
    "k = 71\n",
    "distance = chi_squared_distance\n",
    "\n",
    "# Random Forest \n",
    "num_trees = 100 \n",
    "num_samples_per_leaf = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_data.csv').values\n",
    "X_train = train[:, :-1].copy()\n",
    "X_train_knn = train[:, features].copy()\n",
    "y_train = train[:, -1].copy()\n",
    "y_train_knn = train[:, -1].copy()\n",
    "y_train_knn[y_train_knn==-1] = 0\n",
    "\n",
    "validate = pd.read_csv('data/val_data.csv').values\n",
    "X_val = validate[:, :-1].copy()\n",
    "X_val_knn = validate[:, features].copy()\n",
    "y_val = validate[:, -1].copy()\n",
    "y_val_knn = validate[:, -1].copy()\n",
    "y_val_knn[y_val_knn==-1] = 0\n",
    "\n",
    "test = pd.read_csv('data/test_data.csv').values\n",
    "X_test = test[:, :-1].copy()\n",
    "X_test_knn = test[:, features].copy()\n",
    "y_test = test[:, -1].copy()\n",
    "y_test_knn = test[:, -1].copy()\n",
    "y_test_knn[y_test_knn==-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-0.40193103  0.3601071   0.01985798 ...  4.778956    4.76422315\n",
      "   4.72137961]\n",
      " [-0.18775274  0.19391389  0.0204222  ...  4.35321124  4.40797066\n",
      "   4.46735753]\n",
      " [-0.25534373  0.20556815 -0.01132332 ...  4.6581769   4.73820826\n",
      "   4.7669041 ]\n",
      " ...\n",
      " [-0.19410745  0.20757138  0.03035962 ...  4.41947911  4.42540977\n",
      "   4.44277172]\n",
      " [-0.2780837   0.37422512 -0.00802251 ...  4.56386628  4.63457401\n",
      "   4.64847662]\n",
      " [-0.18197574  0.25089026  0.02713012 ...  4.60340105  4.70450984\n",
      "   4.757542  ]] [ 1. -1. -1. ... -1.  1. -1.]\n",
      "SVM training time: 1108.2112007141113 s\n",
      "[0. 0. 0. ... 0. 0. 0.] 1.7632260883553508\n"
     ]
    }
   ],
   "source": [
    "print(X_train, y_train)\n",
    "alpha, b = train_kernel_svm(X_train, y_train, kernel, C, gamma)\n",
    "print(alpha, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.] 1.7632260883553508\n",
      "0.970105446244157\n",
      "[ 1.99836787 -0.31524533 -0.29591247 ... -0.3660442   1.8863911\n",
      " -0.30773197]\n",
      "SVM eval time: 23.696786165237427 s\n",
      "SVM train: 0.970105446244157\n",
      "0.9539130434782609\n",
      "[-0.30715638 -0.30663783  1.763227   ... -0.40105281 -0.30068552\n",
      " -0.15634671]\n",
      "SVM eval time: 2.7591071128845215 s\n",
      "SVM val: 0.9539130434782609\n"
     ]
    }
   ],
   "source": [
    "print(alpha, b)\n",
    "score, _, _ = svm_score(alpha, b, X_train, y_train, X_train, y_train, kernel, gamma)\n",
    "print(\"SVM train:\", score)\n",
    "\n",
    "score, _, _ = svm_score(alpha, b, X_train, y_train, X_val, y_val, kernel, gamma)\n",
    "print(\"SVM val:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNN training time: 0.022972822189331055 s\n"
     ]
    }
   ],
   "source": [
    "knn = train_knn(X_train_knn, y_train_knn, distance, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNN eval time: 22.549869060516357 s\nKNN train: 0.9613001413197086\n"
     ]
    }
   ],
   "source": [
    "score, _, _ = knn.score(X_train_knn.T, y_train_knn)\n",
    "print(\"KNN train:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Forest training time: 397.1856937408447 s\n"
     ]
    }
   ],
   "source": [
    "random_forest = train_rfc(X_train, y_train, num_trees, num_samples_per_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Forest eval time: 3.045464515686035 s\nRandom Forest train: 0.9630394608109577\n"
     ]
    }
   ],
   "source": [
    "score, _, _ = random_forest.score(X_train, y_train)\n",
    "print(\"Random Forest train:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_predict(X, y):\n",
    "    predictor_svm = get_pred_kernel_svm(alpha, b, X, y, kernel, gamma)\n",
    "    return np.array([predictor_svm(x) for x in X])\n",
    "\n",
    "def knn_predict(X, y):\n",
    "    pred = knn.predict(X.T)\n",
    "    pred[pred==0] = -1\n",
    "    return knn.predict(X.T)\n",
    "\n",
    "def rfc_predict(X, y):\n",
    "    return random_forest.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic voting ensemble classifier:\n",
    "def pred_basic_ensemble(X, y, X_knn, y_knn):\n",
    "    from scipy import stats\n",
    "\n",
    "    svm_pred = svm_predict(X, y)\n",
    "    knn_pred = knn_predict(X_knn, y_knn)\n",
    "    rfc_pred = rfc_predict(X, y)\n",
    "    all_preds = np.array([svm_pred, knn_pred, rfc_pred])\n",
    "    \n",
    "    final_preds = stats.mode(all_preds, axis=0)[0].flatten()\n",
    "    return final_preds\n",
    "\n",
    "def score_basic_ensemble(X, y, X_knn, y_knn):\n",
    "    preds = pred_basic_ensemble(X, y, X_knn, y_knn)\n",
    "    for i in preds.shape[0]:\n",
    "        if preds[i] != 1 and preds[i] != -1:\n",
    "            print(preds[i])\n",
    "    score = np.sum(preds == y) / len(y)\n",
    "    precision = precision_score(y, preds, average='binary')\n",
    "    recall = recall_score(y, pred, average='binary')\n",
    "\n",
    "    return score, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-495fc689e7ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_basic_ensemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_knn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_knn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train error:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_basic_ensemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val_knn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val_knn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"val error:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-48-0c8873755912>\u001b[0m in \u001b[0;36mscore_basic_ensemble\u001b[1;34m(X, y, X_knn, y_knn)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mscore_basic_ensemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_knn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_knn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_basic_ensemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_knn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_knn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpreds\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "score, precision, recall = score_basic_ensemble(X_train, y_train, X_train_knn, y_train_knn)\n",
    "print(\"train error:\", 1 - score)\n",
    "\n",
    "score, precision, recall = score_basic_ensemble(X_val, y_val, X_val_knn, y_val_knn)\n",
    "print(\"val error:\", 1 - score)\n",
    "\n",
    "score, precision, recall = score_basic_ensemble(X_test, y_test, X_test_knn, y_test_knn)\n",
    "print(\"test error:\", 1 - score)\n",
    "print(\"test precision:\", precision)\n",
    "print(\"test recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear svm for stacking ensemble\n",
    "def train_svm(X, y, C=1, print_matrix=False):\n",
    "    \"\"\"\n",
    "    inputs\n",
    "    X: data matrix, shape (N, d)\n",
    "    y: label matrix, shape (N,)\n",
    "    C: coefficient of slack terms in primal optimization, scalar \n",
    "    \n",
    "    returns\n",
    "    w: weight, shape (N,)\n",
    "    b: bias, scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    Xy = X * y.reshape(N, 1)\n",
    "    P = Xy.dot(Xy.T)\n",
    "    q = -np.ones(N)\n",
    "\n",
    "    G = np.concatenate((np.eye(N), -np.eye(N)))\n",
    "    h = np.concatenate((C * np.ones(N), np.zeros(N)))\n",
    "\n",
    "    A = y.reshape(1, N)\n",
    "    b = np.zeros(1)\n",
    "\n",
    "    sol = solvers.qp(matrix(P), matrix(q), matrix(G), matrix(h), matrix(A), matrix(b))\n",
    "    alphas = np.array(sol['x'])\n",
    "    alphas[alphas < 1e-4] = 0\n",
    "    \n",
    "    w = (alphas.reshape(N, 1) * y.reshape(N, 1) * X).sum(axis=0)\n",
    "    b = (y - X.dot(w))[(0 < alphas.reshape(N)) & (alphas.reshape(N) < C - 1e-4)].mean()\n",
    "    return w, b\n",
    "\n",
    "def get_pred_svm(w, b):\n",
    "    return lambda x: w.dot(x) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking ensemble\n",
    "# use linear SVM for meta-learning\n",
    "def train_stacking_ensemble(X, y, X_knn, y_knn, C=1):\n",
    "    svm_pred = svm_predict(X, y)\n",
    "    knn_pred = knn_predict(X_knn, y_knn)\n",
    "    rfc_pred = rfc_predict(X, y)\n",
    "    all_preds = np.array([svm_pred, knn_pred, rfc_pred])\n",
    "    \n",
    "    svm_input = all_preds.T\n",
    "    return train_svm(svm_input, y, C) # use linear kernel by default \n",
    "\n",
    "def pred_stacking_ensemble(X, y, X_knn, y_knn, w, w0):\n",
    "    print(w, w0)\n",
    "\n",
    "    svm_pred = svm_predict(X, y)\n",
    "    knn_pred = knn_predict(X_knn, y_knn)\n",
    "    rfc_pred = rfc_predict(X, y)\n",
    "    all_preds = np.array([svm_pred, knn_pred, rfc_pred])\n",
    "\n",
    "    lin_svm_pred = get_pred_svm(w, w0)\n",
    "    return np.array([lin_svm_pred(x) for x in X])\n",
    "\n",
    "def score_stacking_ensemble(X, y, X_knn, y_knn, w, w0):\n",
    "    preds = pred_stacking_ensemble(X, y, X_knn, y_knn, w, w0)\n",
    "\n",
    "    score = np.sum(preds == y) / len(y)\n",
    "    precision = precision_score(y, preds, average='binary')\n",
    "    recall = recall_score(y, preds, average='binary')\n",
    "\n",
    "    return score, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C = 0.01\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pred_kernel_svm' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-31d120939853>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mC_val\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mC_ensemble\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_stacking_ensemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_knn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_knn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_stacking_ensemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_knn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_knn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-f332454ddc9c>\u001b[0m in \u001b[0;36mtrain_stacking_ensemble\u001b[1;34m(X, y, X_knn, y_knn, C)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# use linear SVM for meta-learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_stacking_ensemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_knn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_knn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0msvm_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mknn_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_knn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_knn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mrfc_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfc_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-bd0c7da5020a>\u001b[0m in \u001b[0;36msvm_predict\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msvm_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mpredictor_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_pred_kernel_svm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpred_kernel_svm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mknn_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-bd0c7da5020a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msvm_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mpredictor_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_pred_kernel_svm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpred_kernel_svm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mknn_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pred_kernel_svm' is not defined"
     ]
    }
   ],
   "source": [
    "C_ensemble = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for C_val in C_ensemble:\n",
    "    print(\"C =\", C_val)\n",
    "    w, w0 = train_stacking_ensemble(X_train, y_train, X_train_knn, y_train_knn, C_val)\n",
    "    \n",
    "    score, precision, recall = score_stacking_ensemble(X_train, y_train, X_train_knn, y_train_knn, w, w0)\n",
    "    print(\"train error:\", 1 - score)\n",
    "\n",
    "    score, precision, recall = score_stacking_ensemble(X_val, y_val, X_val_knn, y_val_knn, w, w0)\n",
    "    print(\"val error:\", 1 - score)\n",
    "\n",
    "    score, precision, recall = score_stacking_ensemble(X_test, y_test, X_test_knn, y_test_knn, w, w0)\n",
    "    print(\"test error:\", 1 - score)\n",
    "    print(\"test precision:\", precision)\n",
    "    print(\"test recall:\", recall)\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}